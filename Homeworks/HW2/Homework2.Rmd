---
title: "PSTAT 174/274, Spring 2023: Homework #2"
author: "Dylan Berneman"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(distributional)
library(ts.extend)
```


Note: {Z~t~} ∼ WN(0,σ~Z~^2^ ) denotes white noise.\

##### Question 1 
Below, you are given the following graphs of autocorrelation functions for three separate data sets, each with n observations. The dotted lines in each graph correspond to 95% confidence intervals. Determine which of the above data sets exhibit statistically significant autocorrelations. Explain how you came to this conclusion.\

```{r echo=FALSE}
knitr::include_graphics("Datasets.png")
```

\setlength{\leftskip}{2cm}

  (A) I only;  
  (B) II only;  
  (C) III only;  
  (D) I, II and III;  
  (E) The answer is not given by (A), (B), (C), or (D).\

  The autocorrelation of the time series at each lag is only significant if the spike reaches past     the significance threshold level.  
  Dataset I is statistically significant at lag 3 and lag 7.  
  Dataset II is statistically significant up to lag 3.  
  Dataset III is not statistically significant at all.  
  Only Datasets I and Dataset II are statistically significant.  
  E.

\setlength{\leftskip}{0cm}
\

#### Question 2

For each of the two time series models, check stationarity and invertibility. Fully justify your answer.\

\setlength{\leftskip}{2cm}

  (a) X~t~ = Z~t~ − $\frac{2}{3}$Z~t−1~ − $\frac{1}{3}$Z~t−2~  

$$
\begin{aligned}
&X_{t}\ \text{is a moving average model, MA(2)}\\
& \text{By definition, moving average models are} \\
& \text{always stationary.}\\
X_{t} &= Z_{t}-\frac{2}{3}Z_{t-1}-\frac{1}{3}Z_{t-2}\\
& = \theta(B)Z_{t}\\
& = 1 -\theta_{1}B\ Z_{t-1} - \theta_{2}B^2\ Z_{t-2}\\
& = 1- \frac{2}{3}B\ Z_{t-1} - \frac{1}{3}B^2\ Z_{t-2}\\
&\theta(z) = 1 - \frac{2}{3}z-\frac{1}{3}z^2\\
z &= \frac{-(-2/3)\ \pm\ \sqrt{(-2/3)^2-4(-1/3)(1)}}{2(-1/3)}\\ \\
&= \frac{2/3\ \pm\ \sqrt{4/9+4/3}}{-2/3}\\\\
&= -1 \pm\ \frac{\sqrt{16/9}}{-2/3}\\\\
& = -1 + \frac{-4/3}{-2/3}\ or\ -1-\frac{4/3}{-2/3}\\
& = 1\ or\ -3\\ \\
&\text{This time series is not invertible.}
\end{aligned}
$$  

\setlength{\leftskip}{0cm}\

\setlength{\leftskip}{2cm}
  (b) X~t~ = (2/3) X~t−1~ + (1/3) X~t−2~ +Z~t~  
  
\setlength{\leftskip}{0cm}
  
  $$
  \begin{aligned}
  &X_{t} = Z_{t}+\frac{2}{3}X_{t-1}+\frac{1}{3}X_{t-2}\\
  &Z_{t} = X_{t}-\frac{2}{3}X_{t-1}-\frac{1}{3}X_{t-2}\\\\
  & \text{Since it is of the form},\ \phi(B)X_{t} = Z_{t},\\
  & \text{it is automatically invertible} \\\\
  &\phi(z) = 1 - \frac{2}{3}z-\frac{1}{3}z^2\\
  z &= \frac{-(-2/3)\ \pm\ \sqrt{(-2/3)^2-4(-1/3)(1)}}{2(-1/3)}\\ \\
  &= \frac{2/3\ \pm\ \sqrt{4/9+4/3}}{-2/3}\\\\
  &= -1 \pm\ \frac{\sqrt{16/9}}{-2/3}\\\\
  & = -1 + \frac{-4/3}{-2/3}\ or\ -1-\frac{4/3}{-2/3}\\
  & = 1\ or\ -3\\ \\
  &\text{This time series is not stationary}
  \end{aligned}
  $$

\setlength{\leftskip}{0cm}
\
\
  
#### Question 3 

\setlength{\leftskip}{2cm}

  (a) For a MA(3) process with coefficients θ~1~ = 2, θ~2~ = 0.5, and θ~3~ = −0.1\
    (i) Write the mathematical equation for MA(3) model with these coefficients\
      $$X_{t} = Z_{t}\ +\ 2\ Z_{t-1}\ +\ 0.5\ Z_{t-2}\ -\ 0.1\ Z_{t-3}$$  
    (ii) Calculate the autocorrelation function at lags 1, 2, 3, 4: ρ(1), ρ(2), ρ(3) and ρ(4)\
$$
\begin{aligned}
\rho(k) &= \frac{\theta_{k}+\theta_{1}\theta_{k+1}+\theta_{2}\theta_{k+2}}{1+\theta_{1}^2+\theta_{2}^2+\theta_{3}^2}\\ \\
\rho(1) &= \frac{\theta_{1}+\theta_{1}\theta_{2}+\theta_{2}\theta_{3}}{1+\theta_{1}^2+\theta_{2}^2+\theta_{3}^2}\\
& = \frac{2+2(0.5)+0.5(-0.1)}{1+2^2+0.5^2+(-0.1)^2}\\
& = 2.95/5.26\\
&=0.5608 \\\\
\rho(2) &= \frac{\theta_{2}+\theta_{1}\theta_{3}+\theta_{2}\theta_{4}}{1+\theta_{1}^2+\theta_{2}^2+\theta_{3}^2}\\ 
&= (0.5+2(-0.1))/5.26\\ 
& = 0.05703\\\\
\rho(3) &= \frac{\theta_{3}+\theta_{1}\theta_{4}+\theta_{2}\theta_{5}}{1+\theta_{1}^2+\theta_{2}^2+\theta_{3}^2}\\ 
&= -0.1/5.26\\
&= -0.019\\\\
\rho(4) &= \frac{\theta_{4}+\theta_{1}\theta_{5}+\theta_{2}\theta_{6}}{1+\theta_{1}^2+\theta_{2}^2+\theta_{3}^2}\\ 
&=0\\
&\rho_X(k)=0, \ k>q
\end{aligned}
$$
    
  (b) For an AR(1) process with coefficient $\phi$~1~ = −0.5, 
    (i) Write the mathematical equation for AR(1) model with these coefficients\
    $$X_{t} = -0.5\ X_{t-1} + Z_{t}$$
    (ii) Calculate the autocorrelation function at lags 1, 2, 3, 4: ρ(1), ρ(2), ρ(3) and ρ(4)\
$$
\begin{aligned}
& \rho_{X}(k) = \phi_{1}^k\\
& \rho(1)= -0.5\\
& \rho(2)= 0.25\\
& \rho(1)= -0.125\\
& \rho(1)= 0.0625\\
\end{aligned}
$$
\setlength{\leftskip}{0cm}
\
\

#### Question 4

You are given the following process: X~t~ = 3 + Y + Z~t~, where Y is a mean zero random variable with variance σ~Y~^2^, independent of the white noise {Z~t~}. Determine whether the process X is stationary and find its autocovariance and autocorrelation functions.\

$$
\begin{aligned}
&X_{t}=3+Y+Z_{t}\\\\
E[X_{t}]&=E[3+Y+Z_{t}]\\
&= E[3]+E[Y]+E[Z_{t}]\\
&= 3 + 0 + 0 = 3 \\\\

& \text{Given that Y is independent from}\ Z_{t},\\
Var[X_{t}] &= Var[3+Y+Z_{t}]\\
&= Var[Y + Z_{t}]\\
&= Var[Y] + Var[Z_{t}] \\
Var[X_t] &= \sigma_{Y}^2 + \sigma_{Z}^2\\
& \text{Since}\ Var[X+Y]=Var[X]+Var[Y]\ \text{if X and Y are independent} \\\\

Cor(X_{t}) = &Cor(3+Y+Z_{t})\\
& \gamma_{X}(0) = Cov(X_{t}, X_{t}) = Var(X_{t})\\
& \text{is independent of all t}
\end{aligned}
$$

\
\

#### Question 5

Let X~t~ = Z~t~ + 2Z~t−1~ − 8Z~t−2~.

\setlength{\leftskip}{2cm}

  (i) Identify the model as the model as MA(q) or AR(p), specify q or p respectively.
  
$$
\begin{aligned}
MA(2)
\end{aligned}
$$
\setlength{\leftskip}{2cm}
  
  (ii) Is the model stationary and invertible? Explain fully and show calculations where needed.
|    (Hint: review 4 from homework 1!)
$$
\begin{aligned}
&\text{All moving average models are stationary.}\\
&\text{Since}\ \theta_{1} = 2,\ \&\ \theta_{2} = -8,\\
& |\theta_{2}| > |\theta_{1}| > 1\\
& \text{The model is not invertible.}
\end{aligned}
$$
\setlength{\leftskip}{2cm}
  
  (iii) Find ρ~X~(2). Use R to simulate 300 values of {X~t~} and use your simulated values to plot sample acf. Compare your sample estimate of ρ~X~(2) to its true value found by calculations. Redo this part using 10,000 simulated values of X~t~.

$$
\begin{aligned}
\rho_{X}(2) &= \frac{\theta_{2}+\theta_{1}\theta_{3}}{1+\theta_{1}^2+\theta_{2}^2}\\\\
&= -8/(1+2^2+(-8)^2)\\
&= -8/69\\
&=-0.1159
\end{aligned}
$$

```{r warning=FALSE}
Z_t <- rnorm(300,0,1)
X_t <- Z_t
X_t[1] = Z_t[1]
X_t[2] = Z_t[2]+2*Z_t[1]
X_t[3:300] = Z_t[3:300]+2*Z_t[2:299]-8*Z_t[1:298]
acf(X_t, lag=2, plot = FALSE)[[1]][[3]]


Z_t <- rnorm(10000,0,1)
X_t <- Z_t
X_t[1] = Z_t[1]
X_t[2] = Z_t[2]+2*Z_t[1]
X_t[3:10000] = Z_t[3:10000]+2*Z_t[2:9999]-8*Z_t[1:9998]
acf(X_t, lag=2, plot = FALSE)[[1]][[3]]
```
\
After testing the range of acf lag 2 values when there are 300 and 10000   
observations, I found that the variance for the acf values with 10000 observations  
is smaller than the variance for the acf values with 300 observation.  
Either way, the mean of acf values for both time series with 300 observations  
and 10000 observations is very close to the theoretical acf at lag 2.
\
\

**The following problems are for students enrolled in PSTAT 274 ONLY**
\

#### Question G1
Let{Z~t~}∼WN(0,1) and {X~t~} be given by X~t~ =Z~t~+θZ~t−2~\  

  (a) Find the autocovariance and autocorrelation function for this process when θ = 0.8\
$$
\begin{aligned}
\gamma_{x}(k)&= 
\begin{cases}1+\theta_{2}^2\ \ \ \ \ \ \ \ for\ \ k = 0\\ \theta_{k}\ \ \ \ \ \ \ \ \ \ \ \ \ \ for\ \ k=2\\ 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ otherwise \end{cases} \\\\
&= \begin{cases}1.64\ \ \ \ \ \ \ \ for\ \ k = 0\\ 0.8\ \ \ \ \ \ \ \ \ \ for\ \ k=2\\ 0 \ \ \ \ \ \ \ \  \ \ \ \ \ otherwise \end{cases} \\\\
\rho_{X}(k) &=
\begin{cases}1\ \ \ \ \ \ \ \ \ \ \ for\ \ k=0\\ \frac{\theta_{k}}{1+\theta_{2}^2}\ \ \ \ \ for\ \ k=\pm 2\\ 0 \ \ \ \ \ \ \ \ \ \ \ otherwise \end{cases} \\\\
&= \begin{cases}1\ \ \ \ \ \ \  \ \ \ \ \ \ \ for\ \ k=0\\ 0.4878\ \ \ \ \ for\ \ k=\pm 2\\ 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \  otherwise \end{cases} 
\end{aligned}
$$
  
  
  (b) Compute the variance of the sample mean (X~1~ + X~2~ + X~3~ + X~4~)/4 when θ = 0.8\
$$
\begin{aligned}
\theta = 0.8\\\\
Var[\frac{X_{1}+X_{2}+X_{3}+X_{4}}{4}] &= (Var[X_{1}]+ Var[X_{2}]+ Var[X_{3}]+ Var[X_{4}]+ 2Cov[X_{2}, X_{4}] + 2Cov[X_{1}, X_{3}])/16\\\\
Var[X_{t}] = \sigma_{Z}^2(1 + \theta^2), &\ \ \ \ \ \ \ \ \ \ \ \ \ Cov(X_{t}, X_{t+k}) = \sigma_{Z}^2(\theta_{k})\\
&=\frac{1}{16}\ [4(1+\theta_{2}^2) + 4\theta]\\
&=\frac{1+\theta_{2}^2+\theta_{2}}{4}\\\\
&=[1+0.64+0.8]/4\\
&=0.61
\end{aligned}
$$
  
  (c) Repeat (b) when θ = −0.8 and compare your answer with the result obtained in (b)\
  
$$
\begin{aligned}
\theta = -0.8\\\\
Var[\frac{X_{1}+X_{2}+X_{3}+X_{4}}{4}] &= (Var[X_{1}]+ Var[X_{2}]+ Var[X_{3}]+ Var[X_{4}]+ 2Cov[X_{2}, X_{4}] + 2Cov[X_{1}, X_{3}])/16\\\\
Var[X_{t}] = \sigma_{Z}^2(1 + \theta^2), &\ \ \ \ \ \ \ \ \ \ \ \ \ Cov(X_{t}, X_{t+k}) = \sigma_{Z}^2(\theta_{k})\\
&=\frac{1}{16}\ [4(1+\theta_{2}^2) - 4\theta]\\
&=\frac{1+\theta_{2}^2-\theta_{2}}{4}\\\\
&=[1+0.64-0.8]/4\\
&=0.41
\end{aligned}
$$
  
\
\

#### Question G2
Provide at least two examples of AR(2) models with autocovariance functions exhibiting very different behavior pattern. Include plots of corresponding theoretical acfs and the corresponding R code.
```{r}
ar2a <- arima.sim(model=list(ar=c(0.5, 0.4)), n=100, sd=1)
acf(ar2a, type="covariance")

ar2b <- arima.sim(model=list(ar=c(0.8, -0.4)), n=100, sd=1)
acf(ar2b, type="covariance")

#Set the parameters
AR    <- c(0.8, -0.4)
sigma <- 1

#Compute auto-covariance function up to length n
plot((sigma^2)*ts.extend::ARMA.autocov(n = 10, ar = AR))

#Set the parameters
AR    <- c(0.8, 0.4)
sigma <- 1

#Compute auto-covariance function up to length n
plot((sigma^2)*ts.extend::ARMA.autocov(n = 10, ar = AR))

```

\
\

#### Question G3
Let X~t~ = Z~t~ + θZ~t−1~, t = 1,2,..., where Z~t~ ∼ IID(0,σ~Z~^2^). 
Show that X~t~ is both weakly and strictly stationary.\
  (Hint: for the last part express the joint moment generating function E $exp(\sum_{i=1}^{n} \lambda_iX_i)$ in terms of function m(λ) = E exp(λZ~i~).)\
  
  
