---
title: "PSTAT 174/274 Spring 2023: Homework 5"
author: "Dylan Berneman"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Note: {Z~t~} ∼ WN(0, σ~Z~^2^) denotes white noise.*

### Question 1
Create a glossary of R-commands for time series. It should contain all commands that you learned so far in the labs, doing homework, and reviewing posted lecture slides. At the minimum, the glossary should include commands that allow:\
  
  - define working directory
  - read and plot data
  - simulate and plot ARMA models\
  - add trend and mean line to the original time series plot\
  - calculate and plot theoretical acf/pacf for ARMA models\
  - calculate and plot sample acf/pacf\
  - check whether a particular model is\ causal/invertible (R commands to find and plot roots of polynomials)\
  - perform Box-Cox transforms\
  - perform differencing data at lags 1 and 12\
  - perform Yule-Walker estimation and find standard deviations of the estimates\
  - perform MLE and check AICC associated with the model\
\

#### Packages
\
**`astsa`**

  - *Applied Statistical Time Series Analysis*\
\

**`tsdl`**

  - *devtools::install_github("FinYang/tsdl")*
  - *Library and practice with time series models*\
\

**`distributional`**

  - *Vectorised distribution objects with tools for manipulating, visualizing, and using probability distributions. Designed to allow model prediction outputs to return distributions rather than their parameters, allowing users to directly interact with predictive distributions in a data-oriented workflow.*\
\

**`FinTS`**

  - *Plot the theoretical ACF corresponding to an ARMA model*\
\

**`FitARMA`**

  - *implements fast maximum likelihood algorithm for fitting ARMA time series*\
\

**`forecast`**

  - *Methods and tools for displaying and analysing univariate time series forecasts including exponential smoothing via state space models and automatic ARIMA modelling.*\
\

**`latex2exp`**

  - *Use LaTeX Expressions in Plots*\
\

**`polynom`**

  - *A Collection of Functions to Implement a Class for Univariate Polynomial Manipulations*\
 \
 
**`readr`**

  - *Read in data*\
\

**`sarima`**

  - *Functions, classes and methods for time series modelling with ARIMA and related models.*\
\

**`tinytex`**

  - *Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents*
```{r message=FALSE, warning=FALSE}
library(devtools)
install.packages('astsa')
install.packages('basicTrendline')
install.packages('distributional')
install.packages('FinTS')
install.packages('FitARMA')
install.packages("forecast")
install.packages('ggplot2')
install.packages('latex2exp')
install.packages('polynom')
install.packages('sarima')

library(astsa)
library(basicTrendline)
devtools::install_github("FinYang/tsdl")
library(tsdl)
library(distributional)
library(dplyr)
library(FinTS)
library(FitARMA)
library(forecast)
library(ggplot2)
library(latex2exp)
library(MASS)
library(polynom)
library(readr)
library(readxl)
library(sarima)
library(tinytex)
```  
\

#### Read and Plot Data
\

read.csv(file = , header)\

  - *`Read` in data (file must be in the same working directory)*\
\

ts(data = " ", start = numeric(0), end = numeric(0), frequency = numeric(0))\

  - *`data` must be a vector, matrix, or data frame*
  - *`start` is the time of the 1^st^ observation*
  - *`frequency` is the number of observations per unit of time*\
\

plot(x, y, xlab = "...", ylab = "...", xlim = c( ), ylim = c( ), main = TeX( ), col = "...")\

  - *`TeX(r'(...$ code $...)')` Render text w/ latex code in place of a string*
  - *`xlab` changes the x-axis label*
  - *`ylab` changes the y-axis label*
  - *`xlim` specify the values on the x-axis*
  - *`ylim` specify the values on the y-axis*
  - *`main` changes the title of the plot*
  - *`col` changes the color of the line*
  - *can also use `plot.ts()` or `ts.plot()`*

```{r, out.width = "30%", fig.align='center'}
# read in data
uspop = read.csv("uspop.txt", header=FALSE)
head(uspop, 5)

# get data from library
milk <- subset(tsdl, 12, "Agriculture")[[3]]

# turn data into time series
data = data.frame("months"=0:24)
data = ts(data, start=1920, end = 1922, frequency=12)
ts.plot(data, main=TeX(r'($\phi$)'), col="red")

```
\

### Simulate and Plot ARMA Models
\

arima(x, order = c(p,d,q), seasonal = list(order = c(P,D,Q), period = S, fixed = c(phi_1.., theta_1..., Phi_1..., Theta_1...)))\

  - *Used for theoretical*
  - *`x` a univariate time series*
  - *`order` specification of the non-seasonal part of the ARIMA model (p,d,q)*
  - *`seasonal` specification of seasonal part of the ARIMA model plus the period (P,D,Q) S*
  - *`fixed` numeric vector of equal length to the coefficients of the sum of the orders of ar, ma, sar, and sma, where NA specifies coefficients to be estimated*\
\

arima.sim(model, n, sd)\

  - *only useful to make a sample model for pure ARIMA*
  - *`model` A list with component ar and/or ma giving the AR and MA coefficients respectively. Optionally a component order can be used. An empty list gives an ARIMA(0, 0, 0) model, that is white noise.*
  - *`n` length of output series, before un-differencing. A strictly positive integer.*
  - *`sd` standard deviation of the rand.gen*\
\

auto.arima(y, d, D, max.p, max.q, max.P, max.Q, max.d, max.D, start.p, start.q, start.P, start.Q, stationary, seasonal, , allowmean, ic)\

  - *Used for theoretical*
  - *Use to fit and estimate model coefficients and parameters using an existing time series *
  - *`y` a univariate time series*
  - *`d` Order of first-differencing. If missing, will choose a value based on test.*
  - *`D` Order of seasonal-differencing. If missing, will choose a value based on season.test.*
  - *`max.p` Maximum value of p*
  - *`max.q` Maximum value of q*
  - *`max.P` Maximum value of P*
  - *`max.Q` Maximum value of Q*
  - *`max.d` Maximum value of d*
  - *`max.D` Maximum value of D*
  - *`start.p` Starting value of p*
  - *`start.q` Starting value of q*
  - *`start.P` Starting value of P*
  - *`start.Q` Starting value of Q*
  - *`stationary` If TRUE, restricts search to stationary models.*
  - *`seasonal` If FALSE, restricts search to non-seasonal models.*
  - *`ic` Information criterion to be used in model selection. c("aicc", "aic", "bic")*
  - *`allowmean`	If TRUE, models with a non-zero mean are considered.*
  - *`astsa::sarima` will provide more output values if parameters are known*\
\

astsa::sarima(xdata, p, d, q, P, D, Q, S)\

  - *Used for theoretical*
  - *`xdata`	univariate time series*
  - *`p` AR order (must be specified)*
  - *`d` difference order (must be specified)*
  - *`q` MA order (must be specified)*
  - *`P` SAR order; use only for seasonal models*
  - *`D` seasonal difference; use only for seasonal models*
  - *`Q` SMA order; use only for seasonal models*
  - *`S` seasonal period; use only for seasonal models*\
\

sarima.for(n.ahead, *same as sarima*)\

  - *`n.ahead` forecast horizon (number of periods)*
\

sarima.sim(ar = NULL, d = 0, ma = NULL, sar = NULL, D = 0, sma = NULL, S = NULL, n = 500, rand.gen = rnorm, innov = NULL, burnin = NA)\

  - *`ar` coefficients of AR component (does not have to be specified)*
  - *`d` order of regular difference (does not have to be specified)*
  - *`ma` coefficients of MA component (does not have to be specified)*
  - *`sar` coefficients of SAR component (does not have to be specified)*
  - *`D` order of seasonal difference (does not have to be specified)*
  - *`sma` coefficients of SMA component (does not have to be specified)*
  - *`S` seasonal period (does not have to be specified)*
  - *`n` desired sample size (defaults to 500)*
  - *`rand.gen` optional; a function to generate the innovations (defaults to normal)*
  - *`innov` an optional times series of innovations. If not provided, rand.gen is used.*
  - *`burnin` length of burn-in (a non-negative integer). If NA (the default) a reasonable value is selected.*\
\

sarima::sarima(model, data = NULL)\

  - *`model` a model formula specifying the model.*
  - *`data` a list or data frame, usually can be omitted.*
    - *`ar(p)` autoregression term of order p*
    - *`ma(q)` moving average term of order q*
    - *`sar(s,p)` seasonal autoregression term (s seasons, order p)*
    - *`sma(s,q)` seasonal moving average term (s seasons, order q)*
    - *`i(d)` (1-B)^d*
    - *`si(d)` (1-B^s)^d*
    - *`s` seasonality*
  - *For ar, ma, sar, sma, values of the coefficients can be specified by an unnamed argument after the parameters given in the descriptions above*
  - *Argument `fixed` can be used to fix some of them. If it is a logical vector it should be of length one or have the same length as the coefficients*
  
```{r, out.width = "30%", fig.align='center'}
# auto.arima
auto_arima = auto.arima(milk, trace = TRUE, D=1, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, seasonal = TRUE)

# sarima_sarima
sarima::sarima(model = milk ~ 
                 ar(1, c(auto_arima$coef[1])) + sar(12, 1, c(auto_arima$coef[2])) + s(12)| sma(12, 1, auto_arima$coef[3]))

# arima
# need to check to see what is wrong
arima = arima(milk, order=c(1,0,0), seasonal = list(order = c(1,1,1), period=12), fixed = c(auto_arima$coef[1], auto_arima$coef[2], auto_arima$coef[3]), include.mean=TRUE, transform.pars=TRUE)

modelOrder(milk, "SarimaFilter")
as.SarimaModel(sim_sarima)

# sim_sarima
sim_sarima = sim_sarima(model = list(ar=auto_arima$coef[1],  sar=auto_arima$coef[3], sma=auto_arima$coef[2], siorder=1, nseasons=12), n=156, x = milk, n.start=1)

new("SarimaModel",)
modelCoef(sim_sarima, convention = "Autocorrelations")
# astsa::sarima
astsa_sarima = astsa::sarima(milk, 1,0,0,1,1,1,12, Model = TRUE)

# Check if methods have same result
unique(astsa_sarima$fit$residuals == auto_arima$residuals)
unique(astsa_sarima$fit$residuals == arima$residuals)
```
\

#### Add Trend and Mean Line
\
decompose(x)\

  - *`x` a time series*
  - *returns the following components: seasonal, figure, trend, random*\
\

stl(x, s.window)\

  - *`x` a time series*
  - *`s.window` string character "periodic"*\
\

abline(a, b)\

  - *`a` intercept of the line*
  - *`b` slope of the line*
  - *mean of a time series will have a = mean(time series) and b = 0*
```{r, out.width = "30%", fig.align='center'}
# Get trend line
x = decompose(milk)

# Plot time series
plot.ts(milk)

# Add trend line
points(x$trend, type = "l", col="red")

# Add Mean Line
abline(a=mean(milk), b=0, col="blue")
```
\

#### Calculate and Plot Theoretical/Sample acf/pacf for ARMA models
\

ARMAacf(ar = numeric(), ma = numeric(), lag.max = r, pacf = FALSE)\

  - *Use to calculate theoretical autocorrelations for pure ARMA models*
  - *Use `plot(ARMAacf(...), type="h); abline(h=0)` to get the plot*
  - *`ar` numeric vector of AR coefficients*
  - *`ma` numeric vector of MA coefficients*
  - *`lag.max` integer. Maximum lag required. Defaults to max(p, q+1), where p, q are the numbers of AR and MA terms respectively.*
  - *`pacf` logical. Should the partial autocorrelations be returned?*\
\

acf(x, )
```{r}
# 
# theoretical
# 
# 
# 
# 
# 
# auto_arima1 = auto.arima(milk, trace = TRUE, max.p = 1, max.q = 0, max.P = 0, max.Q = 0, seasonal = FALSE)
# 
# auto_arima1$fitted
# arima_sim1 = arima.sim(n = 156, model = list(order=c(1,1,0), ar = c(0.6152)), innov = milk, stationary)
# 
# milk
# 
# arima$residuals ==auto_arima$residuals
# # arima
# # need to check to see what is wrong
# arima = arima(milk, order=c(1,0,0), seasonal = list(order = c(1,1,1), period=12), fixed = c(auto_arima$coef[1], auto_arima$coef[2], auto_arima$coef[3]), include.mean=TRUE, transform.pars=TRUE)
# 
# for(x in 1:10){
#   if(sarima_acf[[1]][[x]] == auto_arima_acf[[1]][[x]]){
#     print(TRUE)
#   }
#   else{
#     print(FALSE)
#   }
# }
# arima_acf == auto_arima_acf
# 
# arima_acf = acf(arima$residuals, plot=T, lag.max = 10)
# auto_arima_acf = acf(auto_arima$residuals, plot=T, lag.max = 10)
# sarima_acf = acf(astsa_sarima$fit$residuals, plot=T, lag.max = 10)
# 
# # astsa::sarima
# astsa_sarima = astsa::sarima(milk, 1,0,0,, Model = TRUE)
# 
# pacf(milk)
# plot(ARMAacf(ar = c(0.6, 0.3), ma = c(0.7, 0.6), pacf=T, lag.max = 15), type="h")
# abline(h=0)
# 
# 
# acf(arima.sim(n=100, model = list(order=c(2,0,2), ar = c(0.6, 0.3), ma = c(0.7, 0.6))))
# acf(arima)
# 
# 
# acf(auto_arima$fitted)
# 
# acf(arima)
# 
# 
# abline
# plot(ARMAacf(ar = c(auto_arima$coef[1]), pacf=F)
# plot(ARMAacf(ar = c(auto_arima$coef[1]), pacf=T, plot=F)
# plot(ARMAacf(ar = c(auto_arima$coef[1]), pacf=F, plot=F)
# 
# auto_arima$coef[1], auto_arima$coef[2], auto_arima$coef[3]
# arima$coef
# acf(sarima_sim)
# acf(auto_arima$residuals)
# auto_arima$coef
# acf(astsa_sarima$fit$residuals)
# 
# ts.plot(milk)
# model = list(order = c(1,0,0), seasonal = c(1,1,1)))n=156, ar=0.48, sar=-0.7, sma=0.5, S=12, D=1, innov = milk, burnin = 2)
# plot.ts(smooth(milk))
# plot.ts(milk)
# lines(density(milk))
# arima(milk, order=c(1,0,0), seasonal = list(order=c(1,1,1), period=12))
# armaacf()
# x = auto.arima(milk, trace = TRUE, D=1, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, seasonal = TRUE)
# plot(x$residuals)
# y=astsa::sarima(milk, 1,0,0,1,1,1,12, Model = TRUE)
# acf(x$residuals)
# z = arima(milk, order=c(1,0,0), seasonal=list(order=c(1,1,1), period = 12), fixed = c(0.48, -0.7, 0.5))
# plot(y$fit$residuals)
# points(type="l", x$residuals, col="red")
# acf(z$residuals)
# sim = sarima.sim(n=156, ar=0.48, sar=-0.7, sma=0.5, S=12, D=1, innov = milk, burnin = 2)
# sim
# plot(decompose(milk))
# x = decompose(milk)
# plot.ts(milk)
# points(x$trend, type = "l", col="red")
# abline(a=mean(milk), b=0, type = "l", col="blue")
# 
# 
# ARMAacf(ar=0.6)
# plot(stl(milk, s.window="periodic"))
# trendline(x=1:156, y=milk)
# stat_smooth(milk)
# acf2(y$fit$residuals)
# acf(sim)
# milk[1]
# acf(z$residuals)
# # x=GetFitARMA(milk, p=2, q=0)
# # ImpulseCoefficientsARMA(phi=c(0.9, -0.4), theta = c(0,0.8), 20)
# # ARMAacf(ar=c(0.9,-0.4), ma=c(0,0.8), pacf = TRUE, lag.max = 9)
# # tacvfARMA(phi=c(0.2, -0.6), theta = c(0.5, 0.6), maxLag = 10)
# # TacvfARMA(phi=c(01.2, -0.6), theta = c(0.5, 0.6), lag.max = 10)
# # x
# #
# # polyroot(c(1,3,2))
# # x$fits
# # plot(milk)
# # plot(x$fits)
# # acf2(milk)
# milk <- subset(tsdl, 12, "Agriculture")[[3]]
# InvertibleQ(c(0.8, -0.5))
# z$coef
# x$coef
# y$fit$coef
# pacf(y$fit$residuals)
# x
# y
# milk
# ggplot(milk, aes(x = 1:156, y = milk)) +
#   geom_point() +
#   geom_line(aes(x=1:156, y=milk))+
#   stat_smooth(method = 'loess', aes(colour = 'linear'), se = FALSE) +
#   stat_smooth(method = 'lm', formula = y ~ poly(x,2), aes(colour = 'polynomial'), se= FALSE) +
#   stat_smooth(method = 'nls', formula = y ~ a * log(x) + b, aes(colour = 'logarithmic'), se = FALSE, method.args = list(start = list(a = 1, b = 1)))
```

### Functions

**polyroot(c, b, a,...)**
From: (a(1) - b(B) - c(B^2^)...)(X~t~ or Z~t~)
For X~t~, time series is causal/stationary if |a, b, c| > 1
For Z~t~, time series is invertible if |a, b, c| > 1

```{r}
signature(object = "Autocorrelations", convention = "ComboAutocorrelations", component = "missing")

signature(object = "Autocorrelations", convention = "ComboAutocorrelations", component = "missing") 

signature(object = "Autocorrelations", convention = "PartialAutocorrelations", component = "missing") 

signature(object = "Autocovariances", convention = "Autocorrelations", component = "missing") 

signature(object = "Autocovariances", convention = "ComboAutocorrelations", component = "missing")
  
signature(object = "Autocovariances", convention = "ComboAutocovariances", component = "missing")

signature(object = "Autocovariances", convention = "PartialAutocorrelations", component = "missing") 

signature(object = "ComboAutocorrelations", convention = "Autocorrelations", component = "missing") 

signature(object = "ComboAutocorrelations", convention = "PartialAutocorrelations", component = "missing")

signature(object = "ComboAutocovariances", convention = "Autocovariances", component = "missing") 

signature(object = "ComboAutocovariances", convention = "PartialAutocovariances", component = "missing") 

signature(object = "ComboAutocovariances", convention = "PartialVariances", component = "missing") 

signature(object = "ComboAutocovariances", convention = "VirtualAutocovariances", component = "missing") 

signature(object = "PartialAutocorrelations", convention = "Autocorrelations", component = "missing") 

signature(object = "SarimaModel", convention = "ArFilter", component = "missing")

signature(object = "SarimaModel", convention = "ArmaFilter", component = "missing")

signature(object = "SarimaModel", convention = "MaFilter", component = "missing") 

signature(object = "SarimaModel", convention = "SarimaFilter", component = "missing")

signature(object = "VirtualAutocovariances", convention = "character", component = "missing") 

signature(object = "VirtualAutocovariances", convention = "missing", component = "missing") 

signature(object = "VirtualAutocovariances", convention = "VirtualAutocovariances", component = "missing")

signature(object = "SarimaModel", convention = "ArModel", component = "missing") 

signature(object = "SarimaModel", convention = "MaModel", component = "missing") 

signature(object = "VirtualFilterModel", convention = "BD", component = "missing") 

signature(object = "VirtualFilterModel", convention = "BJ", component = "missing") 

signature(object = "VirtualFilterModel", convention = "character", component = "missing")

signature(object = "VirtualFilterModel", convention = "missing", component = "missing")

signature(object = "VirtualFilterModel", convention = "SP", component = "missing")

signature(object = "ArmaModel", convention = "ArmaFilter", component = "missing")

signature(object = "VirtualAutocovariances", convention = "Autocovariances", component = "missing")
```
  
  
### Question 2
Choose a dataset that you will be interested to analyze for your class final project. URLs of time series libraries are posted on Gaucho Space. Provide the following information about the project:\

  (a) Data set description: briefly describe the data set you plan to use in your project.\
  I want to improve on my final project from PSTAT 231. In that project, my dataset was 2 combined time series of the number of deaths, cases, and vaccinations of the US population per month during the COVID pandemic. It also had the daily historic data and it was all categorized by county and by state within the US. For this project, I will use the daily time series of the smoothed new cases and smoothed new deaths entire United States taken from: https://github.com/owid/covid-19-data/blob/master/public/data/README.md
\

  (b) Motivation and objectives: briefly explain why this data set is interesting or important. Provide a clear description of the problem you plan to address using this dataset (for example to forecast).\
  On my previous project, my goal was to predict the future number of cases and deaths caused by COVID. Now that there are so many lesser strains and variants of COVID, I do not believe that the virus will go away any time soon. I predict that the cases and deaths will continuously decrease over time until cases of COVID become far less severe, and then eventual complete vaccination of the entire country will relegate COVID to a seasonal sickness such as the flu. I want to see how long it will take until the amount of cases and deaths caused by covid resembles those cause by the flu.
\

(c) Plot and examine the main features of the graph, checking in particular whether there is (i) a trend; (ii) a seasonal component, (iii) any apparent sharp changes in behavior. Explain in detail.
```{r}
covid <- read_xlsx("US_COVID_STATS.xlsx")
covid_world <- read.csv("owid-covid-data 2.csv")

covid_world[is.na(covid_world)] <- 0

covid_world <- covid_world %>%
  group_by(date) %>%
  summarise(across(c(total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, new_deaths_smoothed), sum))

covid_world["Total_Case_Fatality_Rate"] = NA
covid_world["New_Case_Fatality_Rate"] = NA
covid_world["Smoothed_New_Case_Fatality_Rate"] = NA

covid_world <- covid_world[1:1225,]

for(i in 1:1225){
  covid_world$Total_Case_Fatality_Rate[i] = covid_world$total_deaths[i] / covid_world$total_cases[i]
  covid_world$New_Case_Fatality_Rate[i] = covid_world$new_deaths[i] / covid_world$new_cases[i]
  covid_world$Smoothed_New_Case_Fatality_Rate[i] = covid_world$new_deaths_smoothed[i] / covid_world$new_cases_smoothed[i]}

covid_world["365Day_Rolling_Fatality"]= NA

for(i in 1:1225){
  if(i >= 376){
    covid_world$`365Day_Rolling_Fatality`[i] = mean(covid_world$New_Case_Fatality_Rate[(i-364):i], na.rm = TRUE)}
  else{
    covid_world$`365Day_Rolling_Fatality`[i] = NA
  }}

Rolling_Fatality <- covid_world[c("365Day_Rolling_Fatality")][376:1225,]

Fatality_Rate = ts(Rolling_Fatality, start = c(2021, 14), frequency = 365)

plot.ts(Fatality_Rate)

ARIMA_model <- auto.arima(Fatality_Rate, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, stationary=FALSE, seasonal = TRUE, trace = TRUE)

plot(decompose(Fatality_Rate))

# The following series is an alternative time series for the project

deaths1 = ts(covid_world$new_deaths, start = c(2020,3), frequency=365)
deaths2 = ts(covid_world$new_deaths, start = c(2020,3))

auto.arima(deaths1, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, stationary = TRUE, seasonal=TRUE)$coef

auto.arima(deaths1, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, stationary=FALSE, seasonal = TRUE)$coef

plot(stl(deaths1, s.window="periodic"))
plot(decompose(deaths1, type="multiplicative"))
plot(decompose(deaths1, type="additive"))
```
\
Neither of the time series are seasonal even though they both show a seasonal component within their decomposed plots. They both have a trend. The first trend it linear, while the second trend looks similar to a normal distribution. There are no easily observable changes in behavior, but I suspect that there should be one the coincides with the creation of the vaccine.\

(d) Use any necessary transformations to get stationary series. Give a detailed explanation to justify your choice of a particular procedure. If you have used transformation, justify why. If you have used differencing, what lag did you use? Why? Is your series stationary now?\

```{r}
ARIMA_model2 <- auto.arima(Fatality_Rate, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, stationary=TRUE, seasonal = TRUE, trace = TRUE)
polyroot()

t = 1:length(Fatality_Rate)
fit = lm(Fatality_Rate ~ t)
bcTransform = boxcox(Fatality_Rate ~ t,plotit = TRUE)

lambda = bcTransform$x[which(bcTransform$y == max(bcTransform$y))] 
wine.bc = (1/lambda)*(Fatality_Rate^lambda-1)

#log transform
wine.log = log(Fatality_Rate)
# square root transform
wine.sqrt = sqrt(Fatality_Rate)
#Compare transforms
op= par(mfrow=c(2,2))
ts.plot(Fatality_Rate, main = "Original Times Series") 
ts.plot(wine.bc, main = "Box-Cox Transform") 
ts.plot(wine.log, main = "Log Transform") 
ts.plot(wine.sqrt, main = "Square Root Transform")

```

(e) Plot and analyze the ACF and PACF to preliminary identify your model(s): Plot ACF/PACF. What model(s) do they suggest? Explain your choice of p and q here.
If your dataset does not work for you, please comment why. For example, the dataset is too short, exhibits change of behavior, does not look like a second-order process, etc. You might review slide 47 of Week 4, Lecture 8.
Note that you may change the project dataset in the future. This question is designed to help you start planning your the project. Please include plots of corresponding theoretical acfs and the corresponding R code.
3. An ARMA(3, 0) model is fit to the following quarterly time series:
  The estimated coefficients are:
ar1 ar2 0.252 0.061
ar3 intercept -0.202 2.637
Year 2018 2019 2020
Quarter 1 3.53
0.98 2.91
Quarter 2 1.33
3.61 2.12
Quarter 3 1.85 3.44 4.62
Quarter 4 0.61 3.38 2.93
      Forecast the value for Quarter 1 of 2021. Give full explanation on how you arrived to your answer. Show calculations.
A. Less that 3.00 B. At least 3.00, but less than 3.25 C. At least 3.25, but less than 3.50 D. Atleast 3.50, but less than 3.75 E. At least 3.75.
Important: For models with AR part, the ”intercept” reported in standard output of R is a misnomer. It is actually the mean of the process, so that the fitted model is
Xt − 2.637 = 0.252(Xt−1 − 2.637) + 0.061(Xt−2 − 2.637) − 0.202(Xt−3 − 2.637) + Zt.
4. You are given the following information about an AR(1) model with mean 0: ρ(2) = 0.215, ρ(3) = −0.100, XT = −0.431. Calculate the forecasted value of XT+1.
5. The five models, AR(1), ARMA(1, 1), ARMA(1, 2), ARMA(2, 3), and ARMA(4, 3) are fitted to the same time series.
The models are ranked using Akaike Information Criterion (AIC): AIC
Model Loglikelihood
You are given the following information:
Determine the best model.
= −2× log-likelihood+2 ×(p + q + 2).
   AR(1)
ARMA(1, 1) -641
ARMA(1, 2) -636
ARMA(2, 3) -630
ARMA(4, 3) -629
-650
  The following problems are for students enrolled in PSTAT 274 ONLY
G1. Suppose that in a sample of size 100, we obtain ρˆ(1) = 0.438 and ρˆ(2) = 0.145. Assuming that the data were generated from an MA(1) model, construct approximate 95% confidence intervals for both ρ(1) and ρ(2). Based on these two confidence intervals, are the data consistent with an MA(1) model with θ = 0.6?
Help: (i) Bartlett’s formula, was discussed in §10.3, slides 52, 55 and 56, of week 4. It gives distribution of sample acfs: For
h
is approximately N(ρ,n−1W) with the elements of matrix W computed by Bartelett’s formula:
∞
large sample size n, ρˆwij =X{ρ(k+i)+ρ(k−i)−2ρ(i)ρ(k)}×{ρ(k+j)+ρ(k−j)−2ρ(j)ρ(k)}
(ii) The acf of MA(1) model was calculated in §3.2, week 1, see slide 64.
(iii) To write confidence intervals for ρ(1) and ρ(2) you need to compute wii for i = 1,2 from Bartlett’s formula. For example, for MA(1) one gets w11 = 1 − 3ρ(1)2 + 4ρ(1)4. Recall that wii = 1 + 2ρ(1)2 for i > 1 (Why?).
