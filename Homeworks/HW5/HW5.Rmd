---
title: "PSTAT 174/274 Spring 2023: Homework 5"
author: "Dylan Berneman"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*Note: {Z~t~} ∼ WN(0, σ~Z~^2^) denotes white noise.*

### Question 1
Create a glossary of R-commands for time series. It should contain all commands that you learned so far in the labs, doing homework, and reviewing posted lecture slides. At the minimum, the glossary should include commands that allow:\
  
  - define working directory
  - read and plot data
  - simulate and plot ARMA models\
  - add trend and mean line to the original time series plot\
  - calculate and plot theoretical acf/pacf for ARMA models\
  - calculate and plot sample acf/pacf\
  - check whether a particular model is\ causal/invertible (R commands to find and plot roots of polynomials)\
  - perform Box-Cox transforms\
  - perform differencing data at lags 1 and 12\
  - perform Yule-Walker estimation and find standard deviations of the estimates\
  - perform MLE and check AICC associated with the model\
\

#### Packages
\
**`astsa`**

  - *Applied Statistical Time Series Analysis*\
\

**`tsdl`**

  - *devtools::install_github("FinYang/tsdl")*
  - *Library and practice with time series models*\
\

**`distributional`**

  - *Vectorised distribution objects with tools for manipulating, visualizing, and using probability distributions. Designed to allow model prediction outputs to return distributions rather than their parameters, allowing users to directly interact with predictive distributions in a data-oriented workflow.*\
\

**`FinTS`**

  - *Plot the theoretical ACF corresponding to an ARMA model*\
\

**`FitARMA`**

  - *implements fast maximum likelihood algorithm for fitting ARMA time series*\
\

**`forecast`**

  - *Methods and tools for displaying and analysing univariate time series forecasts including exponential smoothing via state space models and automatic ARIMA modelling.*\
\

**`latex2exp`**

  - *Use LaTeX Expressions in Plots*\
\

**`polynom`**

  - *A Collection of Functions to Implement a Class for Univariate Polynomial Manipulations*\
 \
 
**`readr`**

  - *Read in data*\
\

**`sarima`**

  - *Functions, classes and methods for time series modelling with ARIMA and related models.*\
\

**`tinytex`**

  - *Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents*
```{r message=FALSE, warning=FALSE}
library(devtools)
# install.packages('astsa')
# install.packages('basicTrendline')
# install.packages('distributional')
# install.packages('FinTS')
# install.packages('FitARMA')
# install.packages("forecast")
# install.packages('ggplot2')
# install.packages('latex2exp')
# install.packages('polynom')
# install.packages('sarima')
library(profvis)
library(htmlwidgets)
install.packages("MuMIn")
library(MuMIn)
library(astsa)
library(basicTrendline)
devtools::install_github("FinYang/tsdl")
library(tsdl)
library(distributional)
library(dplyr)
library(FinTS)
library(FitARMA)
library(forecast)
library(ggplot2)
library(latex2exp)
library(MASS)
library(polynom)
library(readr)
library(readxl)
library(sarima)
library(tinytex)
```  
\

#### Read and Plot Data
\

read.csv(file = , header)\

  - *`Read` in data (file must be in the same working directory)*\
\

ts(data = " ", start = numeric(0), end = numeric(0), frequency = numeric(0))\

  - *`data` must be a vector, matrix, or data frame*
  - *`start` is the time of the 1^st^ observation*
  - *`frequency` is the number of observations per unit of time*\
\

plot(x, y, xlab = "...", ylab = "...", xlim = c( ), ylim = c( ), main = TeX( ), col = "...")\

  - *`TeX(r'(...$ code $...)')` Render text w/ latex code in place of a string*
  - *`xlab` changes the x-axis label*
  - *`ylab` changes the y-axis label*
  - *`xlim` specify the values on the x-axis*
  - *`ylim` specify the values on the y-axis*
  - *`main` changes the title of the plot*
  - *`col` changes the color of the line*
  - *can also use `plot.ts()` or `ts.plot()`*

```{r, out.width = "30%", fig.align='center'}
# read in data
uspop = read.csv("uspop.txt", header=FALSE)
head(uspop, 5)

# get data from library
milk <- subset(tsdl, 12, "Agriculture")[[3]]

# turn data into time series
data = data.frame("months"=0:24)
data = ts(data, start=1920, end = 1922, frequency=12)
ts.plot(data, main=TeX(r'($\phi$)'), col="red")

```
\

### Simulate and Plot ARMA Models
\

arima(x, order = c(p,d,q), seasonal = list(order = c(P,D,Q), period = S, fixed = c(phi_1.., theta_1..., Phi_1..., Theta_1...)))\

  - *Used for theoretical*
  - *`x` a univariate time series*
  - *`order` specification of the non-seasonal part of the ARIMA model (p,d,q)*
  - *`seasonal` specification of seasonal part of the ARIMA model plus the period (P,D,Q) S*
  - *`fixed` numeric vector of equal length to the coefficients of the sum of the orders of ar, ma, sar, and sma, where NA specifies coefficients to be estimated*\
\

arima.sim(model, n, sd)\

  - *only useful to make a sample model for pure ARIMA*
  - *`model` A list with component ar and/or ma giving the AR and MA coefficients respectively. Optionally a component order can be used. An empty list gives an ARIMA(0, 0, 0) model, that is white noise.*
  - *`n` length of output series, before un-differencing. A strictly positive integer.*
  - *`sd` standard deviation of the rand.gen*\
\

auto.arima(y, d, D, max.p, max.q, max.P, max.Q, max.d, max.D, start.p, start.q, start.P, start.Q, stationary, seasonal, , allowmean, ic)\

  - *Used for theoretical*
  - *Use to fit and estimate model coefficients and parameters using an existing time series *
  - *`y` a univariate time series*
  - *`d` Order of first-differencing. If missing, will choose a value based on test.*
  - *`D` Order of seasonal-differencing. If missing, will choose a value based on season.test.*
  - *`max.p` Maximum value of p*
  - *`max.q` Maximum value of q*
  - *`max.P` Maximum value of P*
  - *`max.Q` Maximum value of Q*
  - *`max.d` Maximum value of d*
  - *`max.D` Maximum value of D*
  - *`start.p` Starting value of p*
  - *`start.q` Starting value of q*
  - *`start.P` Starting value of P*
  - *`start.Q` Starting value of Q*
  - *`stationary` If TRUE, restricts search to stationary models.*
  - *`seasonal` If FALSE, restricts search to non-seasonal models.*
  - *`ic` Information criterion to be used in model selection. c("aicc", "aic", "bic")*
  - *`allowmean`	If TRUE, models with a non-zero mean are considered.*
  - *`astsa::sarima` will provide more output values if parameters are known*\
\

astsa::sarima(xdata, p, d, q, P, D, Q, S)\

  - *Used for theoretical*
  - *`xdata`	univariate time series*
  - *`p` AR order (must be specified)*
  - *`d` difference order (must be specified)*
  - *`q` MA order (must be specified)*
  - *`P` SAR order; use only for seasonal models*
  - *`D` seasonal difference; use only for seasonal models*
  - *`Q` SMA order; use only for seasonal models*
  - *`S` seasonal period; use only for seasonal models*\
\

sarima.for(n.ahead, *same as sarima*)\

  - *`n.ahead` forecast horizon (number of periods)*
\

sarima.sim(ar = NULL, d = 0, ma = NULL, sar = NULL, D = 0, sma = NULL, S = NULL, n = 500, rand.gen = rnorm, innov = NULL, burnin = NA)\

  - *`ar` coefficients of AR component (does not have to be specified)*
  - *`d` order of regular difference (does not have to be specified)*
  - *`ma` coefficients of MA component (does not have to be specified)*
  - *`sar` coefficients of SAR component (does not have to be specified)*
  - *`D` order of seasonal difference (does not have to be specified)*
  - *`sma` coefficients of SMA component (does not have to be specified)*
  - *`S` seasonal period (does not have to be specified)*
  - *`n` desired sample size (defaults to 500)*
  - *`rand.gen` optional; a function to generate the innovations (defaults to normal)*
  - *`innov` an optional times series of innovations. If not provided, rand.gen is used.*
  - *`burnin` length of burn-in (a non-negative integer). If NA (the default) a reasonable value is selected.*\
\

sarima::sarima(model, data = NULL)\

  - *`model` a model formula specifying the model.*
  - *`data` a list or data frame, usually can be omitted.*
    - *`ar(p)` autoregression term of order p*
    - *`ma(q)` moving average term of order q*
    - *`sar(s,p)` seasonal autoregression term (s seasons, order p)*
    - *`sma(s,q)` seasonal moving average term (s seasons, order q)*
    - *`i(d)` (1-B)^d*
    - *`si(d)` (1-B^s)^d*
    - *`s` seasonality*
  - *For ar, ma, sar, sma, values of the coefficients can be specified by an unnamed argument after the parameters given in the descriptions above*
  - *Argument `fixed` can be used to fix some of them. If it is a logical vector it should be of length one or have the same length as the coefficients*
  
```{r, out.width = "30%", fig.align='center'}
# auto.arima
auto_arima = auto.arima(milk, D=1, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, seasonal = TRUE)

# sarima_sarima
# sarima::sarima(model = milk ~ 
#                  ar(1, c(auto_arima$coef[1])) + sar(12, 1, c(auto_arima$coef[2])) + s(12)| sma(12, 1, auto_arima$coef[3]))

# arima
# need to check to see what is wrong
arima = arima(milk, order=c(1,0,0), seasonal = list(order = c(1,1,1), period=12), fixed = c(auto_arima$coef[1], auto_arima$coef[2], auto_arima$coef[3]), include.mean=TRUE, transform.pars=TRUE)

# sim_sarima
sim_sarima = sim_sarima(model = list(ar=auto_arima$coef[1],  sar=auto_arima$coef[3], sma=auto_arima$coef[2], siorder=1, nseasons=12), n=156, x = milk, n.start=1)

# astsa::sarima
astsa_sarima = astsa::sarima(milk, 1,0,0,1,1,1,12, Model = TRUE)

# Check if methods have same result
unique(astsa_sarima$fit$residuals == auto_arima$residuals)
unique(astsa_sarima$fit$residuals == arima$residuals)
```
\

#### Add Trend and Mean Line
\
decompose(x)\

  - *`x` a time series*
  - *returns the following components: seasonal, figure, trend, random*\
\

stl(x, s.window)\

  - *`x` a time series*
  - *`s.window` string character "periodic"*\
\

abline(a, b)\

  - *`a` intercept of the line*
  - *`b` slope of the line*
  - *mean of a time series will have a = mean(time series) and b = 0*
```{r, out.width = "30%", fig.align='center'}
# Get trend line
x = decompose(milk)

# Plot time series
plot.ts(milk)

# Add trend line
points(x$trend, type = "l", col="red")

# Add Mean Line
abline(a=mean(milk), b=0, col="blue")
```
\

#### Calculate and Plot Theoretical/Sample acf/pacf for ARMA models
\

ARMAacf(ar = numeric(), ma = numeric(), lag.max = r, pacf = FALSE)\

  - *Use to calculate theoretical autocorrelations for pure ARMA models*
  - *Use `plot(ARMAacf(...), type="h); abline(h=0)` to get the plot*
  - *`ar` numeric vector of AR coefficients*
  - *`ma` numeric vector of MA coefficients*
  - *`lag.max` integer. Maximum lag required. Defaults to max(p, q+1), where p, q are the numbers of AR and MA terms respectively.*
  - *`pacf` logical. Should the partial autocorrelations be returned?*\
\

acf(x, )
```{r}
# 
# theoretical
# 
# 
# 
# 
# 
# auto_arima1 = auto.arima(milk, trace = TRUE, max.p = 1, max.q = 0, max.P = 0, max.Q = 0, seasonal = FALSE)
# 
# auto_arima1$fitted
# arima_sim1 = arima.sim(n = 156, model = list(order=c(1,1,0), ar = c(0.6152)), innov = milk, stationary)
# 
# milk
# 
# arima$residuals ==auto_arima$residuals
# # arima
# # need to check to see what is wrong
# arima = arima(milk, order=c(1,0,0), seasonal = list(order = c(1,1,1), period=12), fixed = c(auto_arima$coef[1], auto_arima$coef[2], auto_arima$coef[3]), include.mean=TRUE, transform.pars=TRUE)
# 
# for(x in 1:10){
#   if(sarima_acf[[1]][[x]] == auto_arima_acf[[1]][[x]]){
#     print(TRUE)
#   }
#   else{
#     print(FALSE)
#   }
# }
# arima_acf == auto_arima_acf
# 
# arima_acf = acf(arima$residuals, plot=T, lag.max = 10)
# auto_arima_acf = acf(auto_arima$residuals, plot=T, lag.max = 10)
# sarima_acf = acf(astsa_sarima$fit$residuals, plot=T, lag.max = 10)
# 
# # astsa::sarima
# astsa_sarima = astsa::sarima(milk, 1,0,0,, Model = TRUE)
# 
# pacf(milk)
# plot(ARMAacf(ar = c(0.6, 0.3), ma = c(0.7, 0.6), pacf=T, lag.max = 15), type="h")
# abline(h=0)
# 
# 
# acf(arima.sim(n=100, model = list(order=c(2,0,2), ar = c(0.6, 0.3), ma = c(0.7, 0.6))))
# acf(arima)
# 
# 
# acf(auto_arima$fitted)
# 
# acf(arima)
# 
# 
# abline
# plot(ARMAacf(ar = c(auto_arima$coef[1]), pacf=F)
# plot(ARMAacf(ar = c(auto_arima$coef[1]), pacf=T, plot=F)
# plot(ARMAacf(ar = c(auto_arima$coef[1]), pacf=F, plot=F)
# 
# auto_arima$coef[1], auto_arima$coef[2], auto_arima$coef[3]
# arima$coef
# acf(sarima_sim)
# acf(auto_arima$residuals)
# auto_arima$coef
# acf(astsa_sarima$fit$residuals)
# 
# ts.plot(milk)
# model = list(order = c(1,0,0), seasonal = c(1,1,1)))n=156, ar=0.48, sar=-0.7, sma=0.5, S=12, D=1, innov = milk, burnin = 2)
# plot.ts(smooth(milk))
# plot.ts(milk)
# lines(density(milk))
# arima(milk, order=c(1,0,0), seasonal = list(order=c(1,1,1), period=12))
# armaacf()
# x = auto.arima(milk, trace = TRUE, D=1, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, seasonal = TRUE)
# plot(x$residuals)
# y=astsa::sarima(milk, 1,0,0,1,1,1,12, Model = TRUE)
# acf(x$residuals)
# z = arima(milk, order=c(1,0,0), seasonal=list(order=c(1,1,1), period = 12), fixed = c(0.48, -0.7, 0.5))
# plot(y$fit$residuals)
# points(type="l", x$residuals, col="red")
# acf(z$residuals)
# sim = sarima.sim(n=156, ar=0.48, sar=-0.7, sma=0.5, S=12, D=1, innov = milk, burnin = 2)
# sim
# plot(decompose(milk))
# x = decompose(milk)
# plot.ts(milk)
# points(x$trend, type = "l", col="red")
# abline(a=mean(milk), b=0, type = "l", col="blue")
# 
# 
# ARMAacf(ar=0.6)
# plot(stl(milk, s.window="periodic"))
# trendline(x=1:156, y=milk)
# stat_smooth(milk)
# acf2(y$fit$residuals)
# acf(sim)
# milk[1]
# acf(z$residuals)
# # x=GetFitARMA(milk, p=2, q=0)
# # ImpulseCoefficientsARMA(phi=c(0.9, -0.4), theta = c(0,0.8), 20)
# # ARMAacf(ar=c(0.9,-0.4), ma=c(0,0.8), pacf = TRUE, lag.max = 9)
# # tacvfARMA(phi=c(0.2, -0.6), theta = c(0.5, 0.6), maxLag = 10)
# # TacvfARMA(phi=c(01.2, -0.6), theta = c(0.5, 0.6), lag.max = 10)
# # x
# #
# # polyroot(c(1,3,2))
# # x$fits
# # plot(milk)
# # plot(x$fits)
# # acf2(milk)
# milk <- subset(tsdl, 12, "Agriculture")[[3]]
# InvertibleQ(c(0.8, -0.5))
# z$coef
# x$coef
# y$fit$coef
# pacf(y$fit$residuals)
# x
# y
# milk
# ggplot(milk, aes(x = 1:156, y = milk)) +
#   geom_point() +
#   geom_line(aes(x=1:156, y=milk))+
#   stat_smooth(method = 'loess', aes(colour = 'linear'), se = FALSE) +
#   stat_smooth(method = 'lm', formula = y ~ poly(x,2), aes(colour = 'polynomial'), se= FALSE) +
#   stat_smooth(method = 'nls', formula = y ~ a * log(x) + b, aes(colour = 'logarithmic'), se = FALSE, method.args = list(start = list(a = 1, b = 1)))
```

### Functions

**polyroot(c, b, a,...)**
From: (a(1) - b(B) - c(B^2^)...)(X~t~ or Z~t~)
For X~t~, time series is causal/stationary if |a, b, c| > 1
For Z~t~, time series is invertible if |a, b, c| > 1
  
  
### Question 2
Choose a dataset that you will be interested to analyze for your class final project. URLs of time series libraries are posted on Gaucho Space. Provide the following information about the project:\

  (a) Data set description: briefly describe the data set you plan to use in your project.\
  I want to improve on my final project from PSTAT 231. In that project, my dataset was 2 combined time series of the number of deaths, cases, and vaccinations of the US population per month during the COVID pandemic. It also had the daily historic data and it was all categorized by county and by state within the US. For this project, I will use the daily time series of the smoothed new cases and smoothed new deaths for the entire world to see when the fatality rate for covid will be as low as it is from the flu. The data was obtained from: https://ourworldindata.org/mortality-risk-covid
\

  (b) Motivation and objectives: briefly explain why this data set is interesting or important. Provide a clear description of the problem you plan to address using this dataset (for example to forecast).\
  On my previous project, my goal was to predict the future number of cases and deaths caused by COVID. Now that there are so many lesser strains and variants of COVID, I do not believe that the virus will go away any time soon. I predict that the cases and deaths will continuously decrease over time until cases of COVID become far less severe, and then eventually, the complete vaccination of the entire the majority of the world population will relegate COVID to a seasonal sickness such as the flu. I want to see how long it will take until the amount of cases and deaths caused by covid resembles those caused by the flu.
\

(c) Plot and examine the main features of the graph, checking in particular whether there is (i) a trend; (ii) a seasonal component, (iii) any apparent sharp changes in behavior. Explain in detail.
```{r}
covid <- read.csv("owid-covid-data 2.csv")

covid[(is.na(covid))]<-0

covid <- covid %>%
  group_by(date) %>%
  summarise(across(c(total_cases, new_cases, new_cases_smoothed, total_deaths, new_deaths, new_deaths_smoothed), sum))

covid["Smoothed_New_Case_Fatality_Rate"] = NA

for(i in 1:1225){
  covid$Smoothed_New_Case_Fatality_Rate[i] = covid$new_deaths_smoothed[i] / covid$new_cases_smoothed[i]}

covid <- covid[346:1225,]

Mortality = ts(covid$Smoothed_New_Case_Fatality_Rate)
frequency(Mortality)
plot.ts(Mortality)
Mortality_acf1 = acf2(Mortality)
var(Mortality)
```

\
There was a sharp change in behavior for my original dataset. This was the time during the pandemic when the vaccine had not been created yet. It was decided that only the daily cases and deaths after the release of the vaccine should be included within the model.

It is too early to tell if there will be a seasonal component since there has only been data for 2.5 years. There does appear to be a negative trend which makes sense because the fatality rate of those who catch covid will continue to decrease as more research is done to create more effective vaccines.
\

(d) Use any necessary transformations to get stationary series. Give a detailed explanation to justify your choice of a particular procedure. If you have used transformation, justify why. If you have used differencing, what lag did you use? Why? Is your series stationary now?\

```{r}
Mortality.diff = diff(Mortality, 1)
plot.ts(Mortality.diff)
Mortality.diff_acf1 = acf2(Mortality.diff)
var(Mortality.diff)

Mortality.diff2 = diff(Mortality, 2)
plot.ts(Mortality.diff2)
Mortality_acf2 = acf2(Mortality.diff2)
var(Mortality.diff2)

# Diff = 1
var(Mortality.diff) < var(Mortality.diff2)
```
\
Testing was done to see if differencing lead to a smaller variance. While the first difference decreased the variance, the second difference increased it, so it was decided that there would be a difference at lag 1. 

\

(e) Plot and analyze the ACF and PACF to preliminary identify your model(s): Plot ACF/PACF. What model(s) do they suggest? Explain your choice of p and q here.
If your dataset does not work for you, please comment why. For example, the dataset is too short, exhibits change of behavior, does not look like a second-order process, etc. You might review slide 47 of Week 4, Lecture 8.
Note that you may change the project dataset in the future. This question is designed to help you start planning your the project. Please include plots of corresponding theoretical acfs and the corresponding R code.
```{r}

ar1 = ar(Mortality.diff, aic = FALSE, method="mle") # 12
ar2 = ar(Mortality.diff, aic = FALSE, method="yw") # 29
ar3 = ar(Mortality.diff, aic = TRUE, method="mle") # 10
ar4 = ar(Mortality.diff, aic = TRUE, order.max = 12, method="yw") # 10

ar1$var.pred
ar2$var.pred
ar3$var.pred
ar4$var.pred

ar1$aic
ar2$aic
ar3$aic
ar4$aic

source("innovations.R")

acvf = acf(Mortality.diff, plot=FALSE, lag.max = length(Mortality.diff))$acf[,1,1] * var(Mortality.diff) 
m = length(acvf)
lh.ia = innovations.algorithm(m+1, acvf)
lh.ia$thetas[9,1:9] # Preliminary estimates of coefficients for MA(9)
lh.ia$thetas[10,1:10] # Preliminary estimates of coefficients for MA(10)
lh.ia$thetas[11,1:11] # Preliminary estimates of coefficients for MA(11)
lh.ia$thetas[12,1:12] # Preliminary estimates of coefficients for MA(12)

arima1 <- auto.arima(Mortality.diff, start.p = 0, start.q = 0, start.P = 0, start.Q = 0, stationary=TRUE, seasonal = TRUE, trace = TRUE) # 5,0,0

fit.ar1 <- arima(Mortality.diff, order=c(5,0,0))
fit.ar2 <- arima(Mortality.diff, order=c(10,0,0))
fit.ar3 <- arima(Mortality.diff, order=c(12,0,0))
fit.ar4 <- arima(Mortality.diff, order=c(29,0,0))

fit.ma5 <- arima(Mortality.diff, order=c(0,0,9))
fit.ma6 <- arima(Mortality.diff, order=c(0,0,10))
fit.ma7 <- arima(Mortality.diff, order=c(0,0,11))
fit.ma8 <- arima(Mortality.diff, order=c(0,0,12))

fit.arma9 <- arima(Mortality.diff, order=c(5,0,9)) # 12/14 0.05 < s.e. < 0.21
fit.arma10 <- arima(Mortality.diff, order=c(5,0,10)) # NAN produced
fit.arma11 <- arima(Mortality.diff, order=c(5,0,11)) # all 0.07 < s.e. < 0.77
fit.arma12 <- arima(Mortality.diff, order=c(5,0,12)) # 13/17 0.05 < s.e. < 0.837

fit.arma13 <- arima(Mortality.diff, order=c(10,0,9)) # NAN produced
fit.arma14 <- arima(Mortality.diff, order=c(10,0,10)) # 18/20  0.05 < s.e. < 0.099
fit.arma15 <- arima(Mortality.diff, order=c(10,0,11)) # all 0.97 < s.e. < 0.32
fit.arma16 <- arima(Mortality.diff, order=c(10,0,12)) # all 0.12 < s.e. < 0.61

fit.arma17 <- arima(Mortality.diff, order=c(12,0,9)) # all 0.05 < s.e. < 0.60
fit.arma18 <- arima(Mortality.diff, order=c(12,0,10)) # NAN produced
fit.arma19 <- arima(Mortality.diff, order=c(12,0,11)) # NAN produced
fit.arma20 <- arima(Mortality.diff, order=c(12,0,12)) # all 0.09 < s.e. < 0.37
fit.arma21 <- arima(Mortality.diff, order=c(29,0,9)) # NAN produced
fit.arma22 <- arima(Mortality.diff, order=c(29,0,10)) # NAN produced
# fit.arma23 <- arima(Mortality.diff, order=c(29,0,11)) # NAN produced
# fit.arma24 <- arima(Mortality.diff, order=c(29,0,12)) # NAN produced

# STATIONARY
fit.arma25_10 <- arima(Mortality.diff, order=c(25,0,10)) # NAN produced
# STATIONARY w/out NANs for s.e. 
fit.arma25_9 <- arima(Mortality.diff, order=c(25,0,9)) # NAN produced

Data <- data.frame(c(AICc(fit.ar1),
AICc(fit.ar2),
AICc(fit.ar3),
AICc(fit.ar4),
AICc(fit.ma5),
AICc(fit.ma6),
AICc(fit.ma7),
AICc(fit.ma8),
AICc(fit.arma9),
AICc(fit.arma10),
AICc(fit.arma11),
AICc(fit.arma12),
AICc(fit.arma13),
AICc(fit.arma14),
AICc(fit.arma15),
AICc(fit.arma16),
AICc(fit.arma17),
AICc(fit.arma18),
AICc(fit.arma19),
AICc(fit.arma20),
AICc(fit.arma21),
AICc(fit.arma22),
AICc(fit.arma25_10),
AICc(fit.arma25_9)))

rownames(Data) <- c("AR(5)", "AR(10)", "AR(12)", "AR(29)", "MA(9)", "MA(10)", "MA(11)", "MA(12)", "ARMA(5,9)", "ARMA(5,10)", "ARMA(5,11)", "ARMA(5,12)", "ARMA(10,9)", "ARMA(10,10)", "ARMA(10,11)", "ARMA(10,12)", "ARMA(12,9)", "ARMA(12,10)", "ARMA(12,11)", "ARMA(12,12)", "ARMA(29,9)", "ARMA(29,10)", "ARMA(25,10)", "ARMA(25,9)")
colnames(Data) <- c("AICc")

Data["Lowest AICc"] <- as.integer(rank(Data$AICc))

acf1 = acf2(fit.ar1$residuals)
acf2 = acf2(fit.ar2$residuals)
acf3 = acf2(fit.ar3$residuals)
acf4 = acf2(fit.ar4$residuals)
acf5 = acf2(fit.ma5$residuals)
acf6 = acf2(fit.ma6$residuals)
acf7 = acf2(fit.ma7$residuals)
acf8 = acf2(fit.ma8$residuals)
acf9 = acf2(fit.arma9$residuals)
acf10 = acf2(fit.arma10$residuals)
acf11 = acf2(fit.arma11$residuals)
acf12 = acf2(fit.arma12$residuals)
acf13 = acf2(fit.arma13$residuals)
acf14 = acf2(fit.arma14$residuals)
acf15 = acf2(fit.arma15$residuals)
acf16 = acf2(fit.arma16$residuals)
acf17 = acf2(fit.arma17$residuals)
acf18 = acf2(fit.arma18$residuals)
acf19 = acf2(fit.arma19$residuals)
acf20 = acf2(fit.arma20$residuals)
acf21 = acf2(fit.arma21$residuals)
acf22 = acf2(fit.arma22$residuals)
acf23 = acf2(fit.arma25_10$residuals)
acf24 = acf2(fit.arma25_9$residuals)

```
\
I used the ar() function to estimate the amount of ar coefficients I should have in my model. The same thing was done using the innovations.R function. I then used the arima function to estimate the coefficients of each different combination of ar and ma orders. It was found that ARIMA(29, 0, 10) made the differenced time series stationary, but there was a concern about many oof the coefficients having NAN values for their standard errors. After seeing that the standard errors for the last few autoregressive coefficients were very small, I tested the effects of decreasing the order by one. This lead me to arrive at ARIMA(25, 0, 10), which was also stationary. By observing the coefficients and seeing that among the many NAN standard error values the 10th moving average coefficient also had NAN as the value for the standard error, I decided to decrease the moving average order by one. Upon doing so, the model remained stationary and there were no NAN values for the standard errors of the coefficients. Therefore, the fitted model for my time series is ARIMA(25,0,9).
\
\

### Question 3
An ARMA(3, 0) model is fit to the following quarterly time series:
```{r}
frame <- data.frame(matrix(ncol=5, nrow=3))
colnames(frame) = c("Year", "Quarter 1", "Quarter 2", "Quarter 3", "Quarter 4")

frame$Year = c(2018, 2019, 2020)
frame$`Quarter 1`= c(3.53, 0.98, 2.91)
frame$`Quarter 2`= c(1.33, 3.61, 2.12)
frame$`Quarter 3`= c(1.85, 3.44, 4.62)
frame$`Quarter 4`= c(0.61, 3.38, 2.93)
frame

frame2 <- data.frame(matrix(ncol=4, nrow=1))
colnames(frame2) = c("ar1", "ar2", "ar3", "Intercept")
frame2[1,] = c(0.252, 0.061, -0.202, 2.637)
frame2
```
\
Forecast the value for Quarter 1 of 2021. Give full explanation on how you arrived to your answer. Show calculations.\

A. Less that 3.00\
B. At least 3.00, but less than 3.25\
C. At least 3.25, but less than 3.50\
D. Atleast 3.50, but less than 3.75\
E. At least 3.75.\
\
Important: For models with AR part, the ”intercept” reported in standard output of R is a misnomer. It is actually the mean of the process, so that the fitted model is\

X~t~ − 2.637 = 0.252(X~t−1~ − 2.637) + 0.061(X~t−2~ − 2.637) − 0.202(X~t−3~ − 2.637) + Z~t~.\

$$
\begin{aligned}
&\ \ \ \ \ E[X_{n+1}|X_1, X_2,...,X_n]\\
&= E[\phi_1X_n + \phi_2X_{n-1}+...+\phi_pX_{n+1-p}+ Z_{n+1}|X_1,X_2,...,X_n]\\
& = 0.252(3.53) + 0.061(0.98) - 0.202(2.91) + 2.637\\
& = 2.99852
\end{aligned}
$$
\
\

### Question 4
You are given the following information about an AR(1) model with mean 0: ρ(2) = 0.215, ρ(3) = −0.100, X~T~ = −0.431. Calculate the forecasted value of X ~T+1~.\
$$
\begin{aligned}
\text{For an AR(1) model, } \rho_k = \phi_1^k\\
\sqrt{0.215} = \pm 0.46368\\
(-0.100)^{1/3} = -0.46368\\
X_{t+1} = -0.46368 * -0.431\\
= 0.20

\end{aligned}
$$
\
\

### Question 5
The five models, AR(1), ARMA(1, 1), ARMA(1, 2), ARMA(2, 3), and ARMA(4, 3) are fitted to the same time series.
The models are ranked using Akaike Information Criterion (AIC): AIC = −2 × log-likelihood+2 ×(p + q + 2).\
You are given the following information:
```{r}
frame2 = data.frame(matrix(ncol=2, nrow=5))
colnames(frame2) = c("Model", "Loglikelihood")
frame2$Model=c("AR(1)", "ARMA(1,1)", "ARMA(1,2)", "ARMA(2,3)", "ARMA(4,3)")
frame2$Loglikelihood=c(-650, -641, -636, -630, -629)
frame2
```
\
Determine the best model.
$$
\begin{aligned}
\ \ \ \ \ \ \ \ \ \ \text{AIC[AR(1)]} &= -2 * -650 + 2*(1+2)\\
&=1306\\
\text{AIC[ARMA(1,1)]} &= -2 * -641 + 2*(1+1+2)\\
&=1290\\
\text{AIC[ARMA(1,2)]} &= -2 * -636 + 2*(1+2+2)\\
&=1282\\
\text{AIC[ARMA(2,3)]} &= -2 * -630 + 2*(2+3+2)\\
&=1274\\
\text{AIC[ARMA(4,3)]} &= -2 * -629 + 2*(4+3+2)\\
&=1276\\\\
\text{The best model is AR(1)}
\end{aligned}
$$
\

 *The following problems are for students enrolled in PSTAT 274 ONLY*
\
\

### Question G1
Suppose that in a sample of size 100, we obtain $\hat{ρ}$(1) = 0.438 and $\hat{ρ}$(2) = 0.145. Assuming that the data were generated from an MA(1) model, construct approximate 95% confidence intervals for both ρ(1) and ρ(2). Based on these two confidence intervals, are the data consistent with an MA(1) model with θ = 0.6?
Help: (i) Bartlett’s formula, was discussed in §10.3, slides 52, 55 and 56, of week 4. It gives distribution of sample acfs: For
h
is approximately N(ρ,n−1W) with the elements of matrix W computed by Bartelett’s formula:
∞
large sample size n, ρˆwij =X{ρ(k+i)+ρ(k−i)−2ρ(i)ρ(k)}×{ρ(k+j)+ρ(k−j)−2ρ(j)ρ(k)}
(ii) The acf of MA(1) model was calculated in §3.2, week 1, see slide 64.
(iii) To write confidence intervals for ρ(1) and ρ(2) you need to compute wii for i = 1,2 from Bartlett’s formula. For example, for MA(1) one gets w11 = 1 − 3ρ(1)2 + 4ρ(1)4. Recall that wii = 1 + 2ρ(1)2 for i > 1 (Why?).
